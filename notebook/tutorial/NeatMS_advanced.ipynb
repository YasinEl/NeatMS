{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes that you have installed NeatMS and familiarised yourself with the tool through the documentation at https://readthedocs.org/NeatMS. Example data and the default model used here are available on [NeatMS github repository](https://github.com/bihealth/NeatMS). The example data is composed of 3 sample files only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting log output (Jupyter notebook specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeatMS uses python standard logging API to facilitate its integration and maintenance in data processing workflow (e.g. [galaxy](https://galaxyproject.org/), [snakemake](https://snakemake.readthedocs.io/en/stable/)). The following code's only purpose is to redirect the logs to the standard output for this tutorial.\n",
    "\n",
    "For more information about python logging API, please see the [official documentation](https://docs.python.org/3.6/library/logging.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import NeatMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing NeatMS is as simple as importing any python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeatMS as ntms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creat experiment object and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a NeatMS experiment object which will automatically load the raw data and the aligned/unaligned features. Set the `raw_data_folder_path` and the `feature_table_path` arguments, both absolute and relative path (from this notebook) are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = '../../data/test_data/mzML/'\n",
    "# Using peaks that have been aligned across samples\n",
    "feature_table_path = '../../data/test_data/aligned_features.csv'\n",
    "# Using unaligned peaks (One individual peak table for each sample)\n",
    "# feature_table_path = '../data/test_data/unaligned_features/'\n",
    "# This is important for NeatMS to read the feature table correctly\n",
    "input_data = 'mzmine'\n",
    "\n",
    "experiment = ntms.Experiment(raw_data_folder_path, feature_table_path, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Manual peak annotation (labelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create an annotation tool object, passing our experiment as an argument so the tool has access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_tool = ntms.AnnotationTool(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's launch the tool and label some peaks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_tool.launch_annotation_tool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you can check how many peaks you have annotated so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_table = experiment.feature_tables[0].annotation_table\n",
    "print(\"Total number of annotated peaks:\",len(annotation_table.labelled_peaks))\n",
    "for annotation in annotation_table.annotations:\n",
    "    print(annotation.label,len(annotation.peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: All those peaks may not be used for training as some of them will not pass the `min_scan_number` that we will set for the neural network, refer to the documentation to learn more about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save manually labelled peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the experiment, which also saves the peaks that you have labelled, is always a good practice to avoid loosing all the manual work put into it. Consider saving the experiment every few hundreds peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can give a name to your experiment before saving\n",
    "# This name will be used as filename (default is `NeatMS_experiment`)\n",
    "experiment.name = 'NeatMS__advanced_tuto'\n",
    "experiment.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Load labelled peaks (experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run this if your have restarted the session, there is no point loading the object that we just saved if it is still in memory. Just skip section 6 entirely otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting a new session here, meaning that you have previously label peaks and are ready to train the Neural network model. Don't forget to first import NeatMS library and set the log output correctly, you will also need to import the `pickle` package to load the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "import NeatMS as ntms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to load the experiment, simply adjust the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = 'NeatMS__advanced_tuto.pkl'\n",
    "with open(pkl_file, 'rb') as f:\n",
    "    experiment = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Neural network training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our network, but first we need to create a `nn_handler` object the same way we did in the basic tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler = ntms.NN_handler(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the 3 batches of data (training, test and validation). You can choose to have the same number of `High_quality`, `Low_quality` and `Noise` peaks in the training batch, for this set `normalise_class` to `true` (default: `False`). Check out the other parameters in the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.create_batches(normalise_class=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the choice to load an existing model or create a new model model. This tutorial does not show how to freeze part of the network for specific tuning using transfer learning. More information and examples are available on the documentation, please, only consider this option if you have experience and feel confortable manipulating neural networks and the Keras/TensorFlow library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the folling line and comment the other two to create a model from scratch\n",
    "# nn_handler.create_model()\n",
    "model_path = \"../../data/model/neatms_default_model.h5\"\n",
    "nn_handler.create_model(model = model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we can make sure that the entire network is not fozen. The model summary tells us how many parameters are trainable/non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.get_model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our network, just pass the number of epochs as parameter. If you want to train your model further, you can simply call `train_model()` once more, the training will resume where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is an example, we set the epochs to 100\n",
    "# This will not be enough when properly training a model\n",
    "nn_handler.train_model(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to get the optimal threshold that should be used with the model that we just trained. This threshold will need to be given as an argument every time we use the model, make sure to store it safely.\n",
    "This threshold can also be manualy chosen, please refer to the documentation for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.get_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets save our model for later use, you can add the threshold as a suffix to the model name so you don't lose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler.class_model.save('my_own_model_threshold.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
