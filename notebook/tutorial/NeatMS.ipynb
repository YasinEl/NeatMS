{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes that you have installed NeatMS and familiarised yourself with the tool through the documentation at https://readthedocs.org/NeatMS. \n",
    "Example data and the default model used here are available on [NeatMS github repository](https://github.com/bihealth/NeatMS). The example data is composed of 3 sample files only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting log output (Jupyter notebook specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeatMS uses python standard logging API to facilitate its integration and maintenance in data processing workflow (*e.g*. [galaxy](https://galaxyproject.org/), [snakemake](https://snakemake.readthedocs.io/en/stable/)). The following code's only purpose is to redirect the logs to the standard output for this tutorial. \n",
    "\n",
    "For more information about python logging API, please see the [official documentation](https://docs.python.org/3.6/library/logging.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import NeatMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing NeatMS is as simple as importing any python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeatMS as ntms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creat experiment object and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a NeatMS experiment object which will automatically load the raw data and the aligned/unaligned features. Set the `raw_data_folder_path` and the `feature_table_path` arguments, both absolute and relative path (from this notebook) are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = '../../data/test_data/mzML/'\n",
    "# Using peaks that have been aligned across samples\n",
    "feature_table_path = '../../data/test_data/aligned_features.csv'\n",
    "# Using unaligned peaks (One individual peak table for each sample)\n",
    "# feature_table_path = '../data/test_data/unaligned_features/'\n",
    "# This is important for NeatMS to read the feature table correctly\n",
    "input_data = 'mzmine'\n",
    "\n",
    "experiment = ntms.Experiment(raw_data_folder_path, feature_table_path, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simple examples on how you can explore MS data using NeatMS.\n",
    "\n",
    "We can already explore the data using NeatMS module. For example, let's print sample names and the number of features present in each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in experiment.samples:\n",
    "    print('Sample {} : {} peaks'.format(sample.name,len(sample.feature_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go further and print the number of feature present in 1, 2, and all 3 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "exp = experiment\n",
    "sizes = []\n",
    "print(\"# Feature collection:\",len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "for consensus_feature in exp.feature_tables[0].feature_collection_list:\n",
    "    sizes.append(len(consensus_feature.feature_list))\n",
    "\n",
    "c = Counter(sizes)\n",
    "print(\"Number of consensus features:\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural network handler object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to create a neural network handler object which will allow us to load an existing model and run it on our data. We just need to pass the `experiment` object to the `NN_handler` so it has access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler = ntms.NN_handler(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the model, the default model is available on NeatMS github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model path (relative and absolute path are both accepted)\n",
    "# Note that model #2 has been tuned to a specific dataset using transfer learning\n",
    "# Here we use the first default base model\n",
    "model_path = \"../../data/model/neatms_default_model.h5\"\n",
    "nn_handler.create_model(model = model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `threshold` parameter needs to be set to predict the peaks present in the dataset. The threshold value for the default NeatMS model distributed on the github repository is `0.22`.\n",
    "\n",
    "When using another model, the threshold value should be given by the person who trained the model. \n",
    "\n",
    "> Threshold for model number 2 is `0.20`.\n",
    "\n",
    "Note: Changing this threshold may have a major impact on the prediction, please read carefully the documentation before adjusting this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold to 0.22\n",
    "threshold=0.22\n",
    "# Run the prediction\n",
    "nn_handler.predict_peaks(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exploring results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before exporting the data, looking through the results can help to decide on the tuning of the parameters of the export function. \n",
    "\n",
    "The code below is similar to the one that prints out the number of peaks present in a certain number of samples (section 4), except that we now have one more level of complexity, the predicted label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "exp = experiment\n",
    "hq_sizes = []\n",
    "lq_sizes = []\n",
    "n_sizes = []\n",
    "sizes = []\n",
    "print(\"# Feature collection:\",len(exp.feature_tables[0].feature_collection_list))\n",
    "for consensus_feature in exp.feature_tables[0].feature_collection_list:\n",
    "    hq_size = 0\n",
    "    lq_size = 0\n",
    "    n_size = 0\n",
    "    for feature in consensus_feature.feature_list:\n",
    "        for peak in feature.peak_list:\n",
    "            if peak.valid:\n",
    "                if peak.prediction.label == \"High_quality\":\n",
    "                    hq_size += 1\n",
    "                if peak.prediction.label == \"Low_quality\":\n",
    "                    lq_size += 1\n",
    "                if peak.prediction.label == \"Noise\":\n",
    "                    n_size += 1\n",
    "\n",
    "    hq_sizes.append(hq_size)\n",
    "    lq_sizes.append(lq_size)\n",
    "    n_sizes.append(n_size)\n",
    "    sizes.append(len(consensus_feature.feature_list))\n",
    "\n",
    "c = Counter(hq_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'High quality':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "c = Counter(lq_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'Low quality':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "c = Counter(n_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'Noise':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that 1130 features are present in all 3 samples in `High_quality`. We could decide to only export those features and be very restrictive, or we can be a bit more conservative and allow `Low_quality` features to be exported under certain conditions. We will see how to do that next using the export function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the export function exports all peaks without filtering, this is our prefered option as it allows keep all the information and filter peaks based on their quality at a later stage using your own criteria (and script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'neatms_export.csv'\n",
    "\n",
    "experiment.export_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also export the data as a pandas dataframe, this is particularly useful when using NeatMS in a python based data analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the dataframe using this function\n",
    "NeatMS_output_df = experiment.export_to_dataframe()\n",
    "# And display it\n",
    "NeatMS_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the information that you export easily using the `export_properties` argument. Here is an example, and the full list of properties that can be exported\n",
    "\n",
    "> Note that the list of properties that can be exported depends on the input data. For example, the `sn` property is only available when the data comes from XCMS (and corresponds to XCMS `sn` value), the same applies to `area_bc` which corresponds to XCMS `intb` value. When a property is not available, it will be set to None in the output dataframe. However, when you ask for a property that does not exists, it will simply be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's add the peak start and end retention time to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add those specific properties to the export list\n",
    "# Default properties will be overwritten, so make sure to add them to the list as well\n",
    "export_properties = [\"rt\", \"mz\", \"height\", \"area\", \"label\", \"peak_rt_start\", \"peak_rt_end\"]\n",
    "\n",
    "# Here is the full list of available properties that you can export\n",
    "# [\"rt\", \"mz\", \"height\", \"area\", \"label\", \"peak_rt_start\", \"peak_rt_end\", \"peak_mz_min\", \"peak_mz_max\", \"area_bc\", \"sn\"]\n",
    "\n",
    "NeatMS_output_df = experiment.export_to_dataframe(export_properties = export_properties)\n",
    "\n",
    "NeatMS_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the function to export the data to a `.csv` file works the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'neatms_export_with_extra_properties.csv'\n",
    "\n",
    "experiment.export_csv(filename, export_properties = export_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The export functions are very flexible and allows precise filtering of the peaks to be exported. Please refer to the documentation for details.\n",
    "\n",
    "For example, the code below exports in a `.csv` file the `height` of the peaks labelled with `High_quality` and `Low_quality`, under the condition that it is present in `High_quality` in a minimum of 2 out of 3 samples. Peaks that do not meet this requirement are discarded. `Noise` labelled peaks are not exported.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'neatms_export.csv'\n",
    "\n",
    "min_group_classes = [\"High_quality\"]\n",
    "min_group_size = 0.66\n",
    "\n",
    "export_classes = [\"High_quality\", \"Low_quality\"]\n",
    "\n",
    "export_properties = [\"rt\", \"mz\", \"height\", \"label\"]\n",
    "\n",
    "experiment.export_csv(filename, export_classes = export_classes, min_group_classes = min_group_classes, min_group_size = min_group_size, export_properties = export_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this tutorial, by now you should be able to load your data into NeatMS and classify the peaks using a pretrained model. For more details on specific function, you can check out the documentation at https://readthedocs.org/NeatMS.\n",
    "\n",
    "If you want to train your own model to better fit your data, take a look at the advanced section of the documentation and check out the advanced tutorial.\n",
    "\n",
    "Thank you for using NeatMS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Extra: Example code to plot peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's extract all `High_quality` peaks from one sample.\n",
    "\n",
    "> Note: You need to have `matplotlib` installed to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"High_quality\",\"Low_quality\",\"Noise\"]\n",
    "# Change the index to plot peaks with different label\n",
    "label = labels[0]\n",
    "\n",
    "sample = experiment.samples[0]\n",
    "\n",
    "peak_count = 0\n",
    "peak_list = []\n",
    "for peak in sample.peak_list:\n",
    "    # This 'valid' statement is important, hotfix for a known issue    \n",
    "    if peak.valid:\n",
    "        if peak.prediction.label == label:\n",
    "            peak_list.append(peak)\n",
    "print('Number of {} peaks in {}: {}'.format(label,sample.name,len(peak_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot 2 peaks (plotting too many take a while, consider saving peaks image files rather than displaying them in a notebook if you want to look at all peaks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(70,72):\n",
    "    peak = peak_list[i]\n",
    "    chromatogram = peak.get_chromatogram(1)\n",
    "    print(i)\n",
    "    plt.plot(chromatogram[0], chromatogram[1])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
