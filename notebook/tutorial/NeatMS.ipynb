{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "# Avoid having to type the full path to import the library\n",
    "library = pathlib.Path('..')\n",
    "sys.path.append(str(library.resolve()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial assumes that you have installed NeatMS and familiarised yourself with the tool through the documentation at https://readthedocs.org/NeatMS. \n",
    "Example data and the default model used here are available on [NeatMS github repository](https://github.com/bihealth/NeatMS). The example data is composed of 3 sample files only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting log output (Jupyter notebook specific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NeatMS uses python standard logging API to facilitate its integration and maintenance in data processing workflow (*e.g*. [galaxy](https://galaxyproject.org/), [snakemake](https://snakemake.readthedocs.io/en/stable/)). The following code's only purpose is to redirect the logs to the standard output for this tutorial. \n",
    "\n",
    "For more information about python logging API, please see the [official documentation](https://docs.python.org/3.6/library/logging.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import NeatMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing NeatMS is as simple as importing any python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeatMS as ntms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creat experiment object and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a NeatMS experiment object which will automatically load the raw data and the aligned/unaligned features. Set the `raw_data_folder_path` and the `feature_table_path` arguments, both absolute and relative path (from this notebook) are accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder_path = '../data/test_data/mzML/'\n",
    "# Using peaks that have been aligned across samples (Recommended)\n",
    "feature_table_path = '../data/test_data/aligned_features.csv'\n",
    "# Using unaligned peaks (One individual peak table for each sample)\n",
    "# feature_table_path = '../data/test_data/unaligned_features/'\n",
    "\n",
    "experiment = ntms.Experiment(raw_data_folder_path, feature_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simple examples on how you can explore MS data using NeatMS.\n",
    "\n",
    "We can already explore the data using NeatMS module. For example, let's print sample names and the number of features present in each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in experiment.samples:\n",
    "    print('Sample {} : {} peaks'.format(sample.name,len(sample.feature_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go further and print the number of feature present in 1, 2, and all 3 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "exp = experiment\n",
    "sizes = []\n",
    "print(\"# Feature collection:\",len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "for consensus_feature in exp.feature_tables[0].feature_collection_list:\n",
    "    sizes.append(len(consensus_feature.feature_list))\n",
    "\n",
    "c = Counter(sizes)\n",
    "print(\"Number of consensus features:\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural network handler object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to create a neural network handler object which will allow us to load an existing model and run it on our data. We just need to pass the `experiment` object to the `NN_handler` so it has access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_handler = ntms.NN_handler(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the model, the default model is available on NeatMS github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model path (relative and absolute path are both accepted)\n",
    "model_path = \"neatms_default_model.h5\"\n",
    "nn_handler.create_model(model = model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `threshold` parameter needs to be set to predict the peaks present in the dataset. The threshold value for the default NeatMS model distributed on the github repository is `0.22`.\n",
    "\n",
    "When using another model, the threshold value should be given by the person who trained the model. \n",
    "\n",
    "Note: Changing this threshold may have a major impact on the prediction, please read carefully the documentation before adjusting this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the threshold to 0.22\n",
    "threshold=0.22\n",
    "# Run the prediction\n",
    "nn_handler.predict_peaks(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Exploring results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before exporting the data, looking through the results can help to decide on the tuning of the parameters of the export function. \n",
    "\n",
    "The code below is similar to the one that prints out the number of peaks present in a certain number of samples (section 4), except that we now have one more level of complexity, the predicted label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import Counter\n",
    "exp = experiment\n",
    "hq_sizes = []\n",
    "lq_sizes = []\n",
    "n_sizes = []\n",
    "sizes = []\n",
    "print(\"# Feature collection:\",len(exp.feature_tables[0].feature_collection_list))\n",
    "for consensus_feature in exp.feature_tables[0].feature_collection_list:\n",
    "    hq_size = 0\n",
    "    lq_size = 0\n",
    "    n_size = 0\n",
    "    for feature in consensus_feature.feature_list:\n",
    "        for peak in feature.peak_list:\n",
    "            if peak.valid:\n",
    "                if peak.prediction.label == \"High_quality\":\n",
    "                    hq_size += 1\n",
    "                if peak.prediction.label == \"Low_quality\":\n",
    "                    lq_size += 1\n",
    "                if peak.prediction.label == \"Noise\":\n",
    "                    n_size += 1\n",
    "\n",
    "    hq_sizes.append(hq_size)\n",
    "    lq_sizes.append(lq_size)\n",
    "    n_sizes.append(n_size)\n",
    "    sizes.append(len(consensus_feature.feature_list))\n",
    "\n",
    "c = Counter(hq_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'High quality':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "c = Counter(lq_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'Low quality':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))\n",
    "\n",
    "c = Counter(n_sizes)\n",
    "print(\"\\nNumber of consensus features labeled as 'Noise':\")\n",
    "for size, count in c.most_common():\n",
    "    print(\"   of size %2d : %6d\" % (size, count))\n",
    "print(\"        total : %6d\" % len(exp.feature_tables[0].feature_collection_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know that 1421 features are present in all 3 samples in `High_quality`. We could decide to only export those features and be very restrictive, or we can be a bit more conservative and allow `Low_quality` features to be exported under certain conditions. We will see how to do that next using the export function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The export functions are very flexible and allows precise filtering of the peaks to be exported. Please refer to the documentation for details.\n",
    "\n",
    "For example, the code below exports in a `.csv` file the `height` of the peaks labelled with `High_quality` and `Low_quality`, under the condition that it is present in `High_quality` in a minimum of 2 out of 3 samples. Peaks that do not meet this requirement are discarded. `Noise` labelled peaks are exported as missing values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'neatms_export.csv'\n",
    "\n",
    "min_group_classes = [\"High_quality\"]\n",
    "min_group_size = 0.66\n",
    "\n",
    "export_classes = [\"High_quality\", \"Low_quality\"]\n",
    "\n",
    "export_properties = [\"rt\", \"mz\", \"height\"]\n",
    "\n",
    "experiment.export_csv(filename, export_classes = export_classes, min_group_classes = min_group_classes, min_group_size = min_group_size, export_properties = export_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Export_to_dataframe` function takes the same arguments as `export_csv` except for the ones related to the file export itself (`filename`,`index` and `na_rep`). Calling this function allows us to look at the results directly in the jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_group_classes = [\"High_quality\"]\n",
    "min_group_size = 0.66\n",
    "\n",
    "export_classes = [\"High_quality\", \"Low_quality\"]\n",
    "\n",
    "export_properties = [\"rt\", \"mz\", \"area\"]\n",
    "\n",
    "df = experiment.export_to_dataframe(export_classes = export_classes, min_group_classes = min_group_classes, min_group_size = min_group_size, export_properties = export_properties)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this tutorial, by now you should be able to load your data into NeatMS and classify the peaks using a pretrained model. For more details on specific function, you can check out the documentation at https://readthedocs.org/NeatMS.\n",
    "\n",
    "If you want to train your own model to better fit your data, take a look at the advanced section of the documentation and check out the advanced tutorial.\n",
    "\n",
    "Thanks for using NeatMS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Extra: Example code to plot peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's extract all `High_quality` peaks from one sample.\n",
    "\n",
    "> Note: You need to have `matplotlib` installed to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"High_quality\",\"Low_quality\",\"Noise\"]\n",
    "# Change the index to plot peaks with different label\n",
    "label = labels[0]\n",
    "\n",
    "sample = experiment.samples[0]\n",
    "\n",
    "peak_count = 0\n",
    "peak_list = []\n",
    "for peak in sample.peak_list:\n",
    "    # This 'valid' statement is important, hotfix for a known issue    \n",
    "    if peak.valid:\n",
    "        if peak.prediction.label == label:\n",
    "            peak_list.append(peak)\n",
    "print('Number of {} peaks in {}: {}'.format(label,sample.name,len(peak_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot 2 peaks (plotting too many take a while, consider saving peaks image files rather than in a notebook if you want to look at all peaks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in range(70,72):\n",
    "    peak = peak_list[i]\n",
    "    chromatogram = peak.get_chromatogram(1)\n",
    "    print(i)\n",
    "    plt.plot(chromatogram[0], chromatogram[1])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
